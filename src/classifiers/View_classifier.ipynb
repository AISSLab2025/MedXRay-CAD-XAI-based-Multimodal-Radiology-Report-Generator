{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3d1a9d-39ed-4310-92d2-bf88084cf7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision.models import densenet121\n",
    "from torchvision.models.densenet import DenseNet121_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7577bc24-887a-4840-96bc-b97f1ae2a4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad65c10-5dda-41ab-99b6-98d08bc88b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = 'classify_images_frontal_lateral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d0fe70-e7b6-4f1c-86e8-95412d52e32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=[]\n",
    "labels=[]\n",
    "for file in os.listdir(BASE_PATH):\n",
    "    if file=='frontal':\n",
    "        for c in os.listdir(os.path.join(BASE_PATH, file)):\n",
    "            if c!='annotations':\n",
    "                image.append(c)\n",
    "                labels.append('frontal')\n",
    "    if file=='lateral':\n",
    "        for c in os.listdir(os.path.join(BASE_PATH, file)):\n",
    "            if c!='annotations':\n",
    "                image.append(c)\n",
    "                labels.append('lateral')\n",
    "data = {'Images':image, 'labels':labels} \n",
    "data = pd.DataFrame(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c5358d-a9c9-4ed2-9e89-3300b798777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "data['encoded_labels'] = lb.fit_transform(data['labels'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa3fe8f-6248-48f2-a9eb-18278b467fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 128\n",
    "train_split = 0.7\n",
    "validation_split = 0.2\n",
    "test_split = 0.1\n",
    "shuffle_dataset = True\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ce79b6-52e8-4948-9ea6-2f520ec743f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset size\n",
    "dataset_size = len(data)\n",
    "indices = list(range(dataset_size))\n",
    "\n",
    "# Calculate split indices\n",
    "train_split_idx = int(np.floor(train_split * dataset_size))\n",
    "validation_split_idx = int(np.floor((train_split + validation_split) * dataset_size))\n",
    "\n",
    "if shuffle_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "# Split indices\n",
    "train_indices = indices[:train_split_idx]\n",
    "val_indices = indices[train_split_idx:validation_split_idx]\n",
    "test_indices = indices[validation_split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbafe419-327b-4aa0-bddc-caa4db873b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6a21c4-199c-4fd5-a2d1-4683d7890595",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of images in training set: {len(train_indices)}')\n",
    "print(f'Number of images in validation set: {len(val_indices)}')\n",
    "print(f'Number of images in test set: {len(test_indices)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709648de-5252-4bb1-8655-9d22baaad40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baaf828-bb6f-470b-b1b7-8046ada0879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MimicCXR_Dataset(Dataset):\n",
    "    def __init__(self, img_data, img_path, transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.transform = transform\n",
    "        self.img_data = img_data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_data)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_name = os.path.join(self.img_path, self.img_data.loc[index, 'labels'],\n",
    "                                self.img_data.loc[index, 'Images'])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        label = torch.tensor(self.img_data.loc[index, 'encoded_labels'], dtype=torch.long)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890e3a28-3b68-4f37-ae24-113c8c79ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MimicCXR_Dataset(data,BASE_PATH,transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32985fd-bc96-4789-8e1c-5377cc0c3f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ca6594-ccd6-4fe1-9237-22d76ac73a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_display(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    npimg = np.transpose(npimg, (1, 2, 0))\n",
    "    return npimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e0c029-d318-4e81-93c4-e62039ff341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "arthopod_types = {0: 'frontal', 1: 'lateral'}\n",
    "# Viewing data examples used for training\n",
    "fig, axis = plt.subplots(3, 5, figsize=(15, 10))\n",
    "for i, ax in enumerate(axis.flat):\n",
    "    with torch.no_grad():\n",
    "        image, label = images[i], labels[i]\n",
    "        ax.imshow(img_display(image)) # add image\n",
    "        ax.set(title = f\"{arthopod_types[label.item()]}\") # add label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d226cf-330b-4013-9d68-8c164b1eebef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNetModel(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(DenseNetModel, self).__init__()\n",
    "        self.densenet = densenet121(weights=DenseNet121_Weights.DEFAULT)\n",
    "        num_ftrs = self.densenet.classifier.in_features\n",
    "        self.densenet.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.densenet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b2445d-b451-4f3f-87e6-8f746238dbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseNetModel().to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f1e45c-6254-41ec-a137-1ef065cf5942",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce22ba8-9042-4ff2-bd34-94e702008135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, labels):\n",
    "    _,pred = torch.max(out, dim=1)\n",
    "    return torch.sum(pred==labels).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e8e5b-717c-46e3-bd74-02f6211d8bbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "print_every = 10\n",
    "valid_loss_min = np.Inf\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    print(f'Epoch {epoch}\\n')\n",
    "    \n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data_, target_) in enumerate(train_loader):\n",
    "        # Move data and target to GPU if available\n",
    "        data_, target_ = data_.to(device), target_.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(data_)\n",
    "        loss = criterion(outputs, target_)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate statistics\n",
    "        running_loss += loss.item()\n",
    "        _, pred = torch.max(outputs, dim=1)\n",
    "        correct += torch.sum(pred == target_).item()\n",
    "        total += target_.size(0)\n",
    "        \n",
    "        # Print progress every 20 batches\n",
    "        if (batch_idx) % 20 == 0:\n",
    "            print(f'Epoch [{epoch}/{n_epochs}], Step [{batch_idx}/{total_step}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    # Calculate accuracy and loss for the epoch\n",
    "    train_acc.append(100 * correct / total)\n",
    "    train_loss.append(running_loss / total_step)\n",
    "    print(f'\\ntrain loss: {np.mean(train_loss):.4f}, train acc: {(100 * correct / total):.4f}')\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    batch_loss = 0\n",
    "    total_t = 0\n",
    "    correct_t = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data_t, target_t in validation_loader:\n",
    "            # Move validation data to GPU\n",
    "            data_t, target_t = data_t.to(device), target_t.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs_t = model(data_t)\n",
    "            loss_t = criterion(outputs_t, target_t)\n",
    "            \n",
    "            # Accumulate validation statistics\n",
    "            batch_loss += loss_t.item()\n",
    "            _, pred_t = torch.max(outputs_t, dim=1)\n",
    "            correct_t += torch.sum(pred_t == target_t).item()\n",
    "            total_t += target_t.size(0)\n",
    "    \n",
    "    # Calculate validation accuracy and loss\n",
    "    val_acc.append(100 * correct_t / total_t)\n",
    "    val_loss.append(batch_loss / len(validation_loader))\n",
    "    network_learned = batch_loss < valid_loss_min\n",
    "    print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t / total_t):.4f}\\n')\n",
    "\n",
    "    # Save model if validation loss improves\n",
    "    if network_learned:\n",
    "        valid_loss_min = batch_loss\n",
    "        torch.save(model.state_dict(), 'model_classification_tutorial.pt')\n",
    "        print('Detected network improvement, saving current model')\n",
    "    model.train()\n",
    "\n",
    "# After training, generate the classification report\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        _, pred = torch.max(output, 1)\n",
    "        all_preds.extend(pred.cpu().numpy())\n",
    "        all_labels.extend(target.cpu().numpy())\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(all_labels, all_preds, target_names=['Frontal', 'Lateral'])\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef0a69b-7eb8-4839-9526-d93038eac00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "# Switch to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Store all predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Turn off gradients for validation\n",
    "with torch.no_grad():\n",
    "    for data_t, target_t in test_loader:\n",
    "        data_t, target_t = data_t.to(device), target_t.to(device)\n",
    "        outputs_t = model(data_t)\n",
    "        _, preds_t = torch.max(outputs_t, 1)\n",
    "        all_preds.append(preds_t.cpu().numpy())\n",
    "        all_labels.append(target_t.cpu().numpy())\n",
    "\n",
    "# Flatten the list of predictions and true labels\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Create the heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "im = ax.imshow(conf_matrix, interpolation='nearest', cmap='Blues')\n",
    "\n",
    "# Add colorbar\n",
    "cbar = ax.figure.colorbar(im, ax=ax)\n",
    "cbar.ax.set_ylabel('Count', rotation=-90, va=\"bottom\")\n",
    "\n",
    "# Set labels\n",
    "ax.set(xticks=np.arange(conf_matrix.shape[1]),\n",
    "       yticks=np.arange(conf_matrix.shape[0]),\n",
    "       xticklabels=['Frontal', 'Lateral'],\n",
    "       yticklabels=['Frontal', 'Lateral'],\n",
    "       ylabel='Actual',\n",
    "       xlabel='Predicted')\n",
    "\n",
    "# Rotate the tick labels and set their alignment\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "# Loop over data dimensions and create text annotations\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        text = ax.text(j, i, str(conf_matrix[i, j]),\n",
    "                       ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "ax.set_title(\"Confusion Matrix\")\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"densenet121_confusion_matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Print the confusion matrix values\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec9db2b-489f-4124-aa34-43e916bf9036",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming all_preds and all_labels are already defined as in the previous code\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(all_labels, all_preds, target_names=['Frontal', 'Lateral'])\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae575a0d-26db-4426-955a-f9558cd361f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_per_class = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
    "class_names = ['Frontal', 'Lateral']\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f\"Accuracy for {class_name}: {accuracy_per_class[i]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d5bab6-7b56-4b11-8d24-91a2722ef030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
