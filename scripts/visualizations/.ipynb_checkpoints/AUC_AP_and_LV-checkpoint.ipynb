{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ffb7f4-8331-4f0f-82c0-b61a9ed47627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report, roc_curve, auc\n",
    "import os\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0120ba-58ce-4a40-90b8-94998b410cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989ad355-599b-46c2-82d4-1fcffeafb897",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"path_to_directory\"\n",
    "dataset = pd.read_csv(\"path_to_directory\")\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5f4f7e-1d99-4485-ab10-621c1bb53b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet121(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet121, self).__init__()\n",
    "        self.densenet121 = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n",
    "        num_ftrs = self.densenet121.classifier.in_features\n",
    "        self.densenet121.classifier = nn.Identity()  # No classifier yet, only features\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.densenet121(x)\n",
    "\n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet50, self).__init__()\n",
    "        self.resnet50 = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        num_ftrs = self.resnet50.fc.in_features\n",
    "        self.resnet50.fc = nn.Identity()  # No classifier yet, only features\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet50(x)\n",
    "\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, out_size):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        # Instantiate DenseNet121 and ResNet50 for frontal and lateral views\n",
    "        self.densenet_frontal = DenseNet121()\n",
    "        self.resnet_frontal = ResNet50()\n",
    "        \n",
    "        self.densenet_lateral = DenseNet121()\n",
    "        self.resnet_lateral = ResNet50()\n",
    "        \n",
    "        # The combined feature size\n",
    "        frontal_feature_size = 1024 + 2048  # Assuming DenseNet121 outputs 1024 and ResNet50 outputs 2048\n",
    "        lateral_feature_size = 1024 + 2048\n",
    "        \n",
    "        combined_feature_size = frontal_feature_size + lateral_feature_size\n",
    "        \n",
    "        # Final classifier layer\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(combined_feature_size, out_size),\n",
    "            nn.Sigmoid()  # Assuming binary classification for multi-label\n",
    "        )\n",
    "        \n",
    "    def forward(self, x_frontal, x_lateral):\n",
    "        # Extract features from DenseNet and ResNet for both views\n",
    "        frontal_features = torch.cat([self.densenet_frontal(x_frontal), self.resnet_frontal(x_frontal)], dim=1)\n",
    "        lateral_features = torch.cat([self.densenet_lateral(x_lateral), self.resnet_lateral(x_lateral)], dim=1)\n",
    "        \n",
    "        # Combine frontal and lateral features\n",
    "        combined_features = torch.cat([frontal_features, lateral_features], dim=1)\n",
    "        \n",
    "        # Final output through classifier\n",
    "        out = self.classifier(combined_features)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f7aa60-450d-4b4d-9916-bde06b62086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LABELS = 14\n",
    "# Load the saved model\n",
    "best_model = CombinedModel(out_size=N_LABELS)\n",
    "best_model.load_state_dict(torch.load('path_to_best_model.pth'))\n",
    "best_model = best_model.to(device)\n",
    "best_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601bc0ec-3aae-4bb5-a49f-927aa46716f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON file with test image paths\n",
    "with open('test_image_paths.json', 'r') as f:\n",
    "    test_image_paths = json.load(f)\n",
    "\n",
    "frontal_images = test_image_paths['frontal_images']\n",
    "lateral_images = test_image_paths['lateral_images']\n",
    "\n",
    "# Ensure the two lists of images align by pairing images correctly\n",
    "assert len(frontal_images) == len(lateral_images), \"Frontal and lateral image lists must have the same length.\"\n",
    "\n",
    "# Prepare arrays for true and predicted labels\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# Classes\n",
    "classes = [\n",
    "    'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum', \n",
    "    'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion', \n",
    "    'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27a5dab-1384-4bf8-a78c-d8dc6ad31533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each pair of frontal and lateral images\n",
    "for frontal_img_path, lateral_img_path in zip(frontal_images, lateral_images):\n",
    "    frontal_full_path = f\"{BASE_PATH}/{frontal_img_path}\"\n",
    "    lateral_full_path = f\"{BASE_PATH}/{lateral_img_path}\"\n",
    "\n",
    "    # Get true labels\n",
    "    true_labels = dataset[dataset['frontal_image'] == frontal_img_path][classes].values[0]\n",
    "    y_true.append(true_labels)\n",
    "\n",
    "    # Load and preprocess images\n",
    "    frontal_img = Image.open(frontal_full_path).convert('RGB')\n",
    "    frontal_img_tensor = transform(frontal_img).unsqueeze(0).to(device)\n",
    "    lateral_img = Image.open(lateral_full_path).convert('RGB')\n",
    "    lateral_img_tensor = transform(lateral_img).unsqueeze(0).to(device)\n",
    "\n",
    "    # Predict labels using the model\n",
    "    with torch.no_grad():\n",
    "        output = best_model(frontal_img_tensor, lateral_img_tensor)\n",
    "    y_pred.append(output.cpu().numpy()[0])  # Storing probabilities instead of binary labels\n",
    "\n",
    "# Convert to numpy arrays\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Compute and display multilabel confusion matrices\n",
    "mcm = multilabel_confusion_matrix(y_true > 0.5, y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2c424c-8236-4afa-9e7d-43459ee24c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "for i, class_name in enumerate(classes):\n",
    "    fpr, tpr, _ = roc_curve(y_true[:, i], y_pred[:, i])\n",
    "    auc_score = roc_auc_score(y_true[:, i], y_pred[:, i])\n",
    "    ax.plot(fpr, tpr, label=f'{class_name} (AUC = {auc_score:.2f})')\n",
    "\n",
    "# Add diagonal line\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "# Add labels and legend\n",
    "ax.set_xlabel(\"False Positive Rate\")\n",
    "ax.set_ylabel(\"True Positive Rate\")\n",
    "ax.set_title(\"ROC Curve for each class\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.savefig('roc_curves_final.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
