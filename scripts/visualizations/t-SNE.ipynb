{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6686d2f2-35fd-4db8-ad0b-153fdd6971b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torchvision.models import densenet121\n",
    "import cv2\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcb4ebb-857d-463c-9dc8-fb0cecbcf1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CLAHE Transform class\n",
    "class CLAHETransform:\n",
    "    def __init__(self, clip_limit=0.10, tile_grid_size=(8, 8)):\n",
    "        self.clip_limit = clip_limit\n",
    "        self.tile_grid_size = tile_grid_size\n",
    "        self.clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if isinstance(img, Image.Image):\n",
    "            img = np.array(img)\n",
    "        if img.ndim == 3:\n",
    "            lab_img = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "            l_channel, a_channel, b_channel = cv2.split(lab_img)\n",
    "            l_channel = self.clahe.apply(l_channel)\n",
    "            lab_img = cv2.merge((l_channel, a_channel, b_channel))\n",
    "            img = cv2.cvtColor(lab_img, cv2.COLOR_LAB2RGB)\n",
    "        else:\n",
    "            img = self.clahe.apply(img)\n",
    "        return Image.fromarray(img.astype('uint8'))\n",
    "\n",
    "# Define the transform pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    CLAHETransform(clip_limit=0.35, tile_grid_size=(8, 8)),\n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class DenseNetModel(nn.Module):\n",
    "    def __init__(self, out_size=14):\n",
    "        super(DenseNetModel, self).__init__()\n",
    "        self.densenet121 = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n",
    "        num_ftrs = self.densenet121.classifier.in_features\n",
    "        self.densenet121.classifier = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, out_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.densenet121(x)\n",
    "\n",
    "# Load your trained DenseNet model\n",
    "model_path = \"path_to_model.pth\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DenseNetModel().to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37addafa-5a35-4381-854d-5f8561a49b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base path for disease-specific images\n",
    "BASE_PATH = \"path_to_directory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e26e45-336b-4e69-a734-e946f1f7cee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features\n",
    "def extract_features(img_path):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img = transform(img).unsqueeze(0).to(device)  # Apply transformations and add batch dimension\n",
    "    with torch.no_grad():\n",
    "        features = model(img)  # Pass the image through the model\n",
    "    return features.cpu().numpy().flatten()  # Convert to NumPy array\n",
    "\n",
    "# Initialize lists to hold features and labels\n",
    "all_features = []\n",
    "all_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1622c5ef-20ca-4a88-9859-2f387f478e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of diseases based on the folder names in the base path\n",
    "disease_folders = [disease for disease in os.listdir(BASE_PATH) if os.path.isdir(os.path.join(BASE_PATH, disease))]\n",
    "\n",
    "# Loop through each disease folder and extract features\n",
    "for i, disease in enumerate(tqdm(disease_folders, desc=\"Processing Diseases\")):\n",
    "    disease_folder_path = os.path.join(BASE_PATH, disease)\n",
    "    image_files = [os.path.join(disease_folder_path, img) for img in os.listdir(disease_folder_path)\n",
    "                   if img.lower().endswith(('.jpg', '.jpeg', '.png')) and os.path.isfile(os.path.join(disease_folder_path, img))]\n",
    "\n",
    "    # Skip folders with no valid images\n",
    "    if not image_files:\n",
    "        print(f\"No valid image files found in {disease_folder_path}. Skipping this folder.\")\n",
    "        continue\n",
    "\n",
    "    # Select up to 300 images for this disease\n",
    "    if len(image_files) > 1000:\n",
    "        image_files = np.random.choice(image_files, 1000, replace=False)\n",
    "\n",
    "    try:\n",
    "        # Extract features for these images\n",
    "        features = np.array([extract_features(img_path) for img_path in tqdm(image_files, desc=f\"Extracting features for {disease}\", leave=False)])\n",
    "        # Append features and labels\n",
    "        all_features.append(features)\n",
    "        all_labels.extend([i] * len(features))\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {disease}: {e}\")\n",
    "\n",
    "# Flatten features and labels into single arrays\n",
    "all_features = np.vstack(all_features)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Perform t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "tsne_results = tsne.fit_transform(all_features)\n",
    "\n",
    "# Plot t-SNE\n",
    "plt.figure(figsize=(10, 8))\n",
    "for label in np.unique(all_labels):\n",
    "    indices = all_labels == label\n",
    "    plt.scatter(tsne_results[indices, 0], tsne_results[indices, 1], label=disease_folders[label], alpha=0.7)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"t-SNE Visualization\")\n",
    "plt.xlabel(\"t-SNE Dimension 1\")\n",
    "plt.ylabel(\"t-SNE Dimension 2\")\n",
    "\n",
    "plt.savefig('t-sne-our-model.png')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
