{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec4086e-714d-4a09-ab98-6eb28ffb6e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import skimage.io\n",
    "import torchxrayvision as xrv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import densenet121\n",
    "import torchvision.models as models\n",
    "import torchvision.models as models\n",
    "import cv2\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.load import dumps, loads\n",
    "from operator import itemgetter\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from adjustText import adjust_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6303e0e5-6351-4da7-9ddd-e1a6388e47d5",
   "metadata": {},
   "source": [
    "### Classification Best model Inferencace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8672d793-0bcd-4ad9-80c2-d01bdbbedfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the labels as used during training\n",
    "labels = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', \n",
    "          'Enlarged Cardiomediastinum', 'Fracture', 'Lung Lesion', 'Lung Opacity', \n",
    "          'No Finding', 'Pleural Effusion', 'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices']\n",
    "\n",
    "class DenseNetModel(nn.Module):\n",
    "    def __init__(self, out_size=14):\n",
    "        super(DenseNetModel, self).__init__()\n",
    "        self.densenet121 = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n",
    "        num_ftrs = self.densenet121.classifier.in_features\n",
    "        self.densenet121.classifier = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, out_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.densenet121(x)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DenseNetModel().to(device)\n",
    "model.load_state_dict(torch.load('path_to_directory'))\n",
    "model.eval()\n",
    "\n",
    "# CLAHE transform class\n",
    "class CLAHETransform:\n",
    "    def __init__(self, clip_limit=0.10, tile_grid_size=(8, 8)):\n",
    "        self.clip_limit = clip_limit\n",
    "        self.tile_grid_size = tile_grid_size\n",
    "        self.clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if isinstance(img, Image.Image):\n",
    "            img = np.array(img)\n",
    "        if img.ndim == 3:\n",
    "            lab_img = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "            l_channel, a_channel, b_channel = cv2.split(lab_img)\n",
    "            l_channel = self.clahe.apply(l_channel)\n",
    "            lab_img = cv2.merge((l_channel, a_channel, b_channel))\n",
    "            img = cv2.cvtColor(lab_img, cv2.COLOR_LAB2RGB)\n",
    "        else:\n",
    "            img = self.clahe.apply(img)\n",
    "        return Image.fromarray(img.astype('uint8'))\n",
    "\n",
    "# Define the validation transform (same as during training)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    CLAHETransform(clip_limit=0.35, tile_grid_size=(8, 8)),\n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "# Function to predict an image\n",
    "def predict_image(image_path):\n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "\n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "    \n",
    "    # Convert predictions to numpy array and map to labels\n",
    "    predictions = output.cpu().numpy().squeeze()  # Remove batch dimension\n",
    "    pred_scores = {labels[i]: predictions[i] for i in range(len(predictions))}\n",
    "    \n",
    "    return pred_scores\n",
    "\n",
    "# Example usage\n",
    "# image_path = r\"'path_to_directory'\" # Real labels for this image {Consolidation, Pleural Effusion, Supporting Device}\n",
    "# pred_scores = predict_image(image_path)\n",
    "# # pred_scores\n",
    "# # Print the scores for each label\n",
    "# for label, score in pred_scores.items():\n",
    "#     print(f'{label}: {score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3b1c31-d6a1-48d0-bb8f-1d45171253e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_classifications(classifications: dict, top_n: int = 3, threshold: float = 0.50) -> dict:\n",
    "    # Filter classifications that are above the threshold\n",
    "    filtered_classifications = {k: v for k, v in classifications.items() if v > threshold}\n",
    "    \n",
    "    # Sort the filtered classifications by their score in descending order\n",
    "    sorted_classifications = sorted(filtered_classifications.items(), key=lambda item: item[1], reverse=True)\n",
    "    \n",
    "    # Return the top N classifications\n",
    "    top_classifications = {k: v for k, v in sorted_classifications[:top_n]}\n",
    "    \n",
    "    return top_classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a52ae02-57d0-4490-ab5f-07a33a971b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_report = \"\"\"\n",
    "EXAMINATION: CHEST (PA AND LAT)\n",
    "\n",
    "INDICATION: ___ with new onset ascites\n",
    "\n",
    "TECHNIQUE: Chest PA and lateral\n",
    "\n",
    "COMPARISON: None.\n",
    "\n",
    "FINDINGS: \n",
    "There is no focal consolidation, pleural effusion or pneumothorax. Bilateral nodular opacities that most likely represent nipple shadows. The cardiomediastinal silhouette is normal. Clips project over the left lung, potentially within the breast. The imaged upper abdomen is unremarkable. Chronic deformity of the posterior left sixth and seventh ribs are noted.\n",
    "\n",
    "IMPRESSION: \n",
    "No acute cardiopulmonary process.\n",
    "\"\"\"\n",
    "\n",
    "report_template = \"\"\"\n",
    "1. EXAMINATION: {examination}\n",
    "2. INDICATION: {indication}\n",
    "3. TECHNIQUE: {technique}\n",
    "4. COMPARISON: {comparison}\n",
    "5. FINDINGS: {findings}\n",
    "6. IMPRESSION: {impression}\n",
    "\"\"\"\n",
    "\n",
    "# def generate_prompt(classification_list):\n",
    "#     classification = \", \".join([f\"{k}: {v:.2f}\" for k, v in classification_list.items()])\n",
    "#     return f\"\"\"\n",
    "#     You are an expert radiologist. Based on the following context, query, and sample report, generate a detailed radiology report.\n",
    "\n",
    "#     classification: {classification}\n",
    "    \n",
    "#     Here's a sample report for reference:\n",
    "#     {sample_report}\n",
    "\n",
    "#     Please structure your report using the following template, maintaining a similar level of detail and professional tone as the sample report:\n",
    "#     {report_template}\n",
    "    \n",
    "#     Important guidelines:\n",
    "#     1. Ensure that each section of the report is filled with relevant and detailed information.\n",
    "#     2. Use clear, concise medical terminology appropriate for radiology reports.\n",
    "#     3. In the FINDINGS section, describe observations systematically, from most to least significant.\n",
    "#     4. In the IMPRESSION section, summarize the key findings and their clinical significance.\n",
    "#     5. Maintain a professional and objective tone throughout the report.\n",
    "#     6. Adapt the level of detail to match the complexity of the examination and findings.\n",
    "#     \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff654e97-459c-470d-8513-ef3b632b19e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciprocal_rank_fusion(results, k=5):\n",
    "    fused_scores = {}\n",
    "    for docs in results:\n",
    "        for rank, doc in enumerate(docs):\n",
    "            doc_str = dumps(doc)\n",
    "            fused_scores[doc_str] = fused_scores.get(doc_str, 0) + 1 / (rank + k)\n",
    "    return [(loads(doc), score) for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cee5065-6a33-457b-a189-4f0b9b8f2dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(query_embedding, doc_embeddings):\n",
    "    query_embedding = np.array(query_embedding).reshape(1, -1)\n",
    "    doc_embeddings = np.array(doc_embeddings)\n",
    "    cosine_similarities = cosine_similarity(query_embedding, doc_embeddings).flatten()\n",
    "    return cosine_similarities\n",
    "\n",
    "def plot_tsne(query_embedding, doc_embeddings, cosine_similarities):\n",
    "    # Combine query and document embeddings for t-SNE\n",
    "    all_embeddings = np.vstack([query_embedding, doc_embeddings])\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=min(5, len(all_embeddings) - 1))\n",
    "    tsne_results = tsne.fit_transform(all_embeddings)\n",
    "\n",
    "    # Separate out query and document t-SNE results\n",
    "    query_tsne = tsne_results[0]\n",
    "    doc_tsne = tsne_results[1:]\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Scatter plot for documents with color-coded cosine similarities\n",
    "    scatter = plt.scatter(doc_tsne[:, 0], doc_tsne[:, 1], marker='o', c=cosine_similarities, cmap=\"coolwarm\", edgecolor=\"k\", s=100)\n",
    "    plt.colorbar(scatter, label=\"Cosine Similarity\")\n",
    "\n",
    "    # Plot the query as a distinct marker\n",
    "    plt.scatter(query_tsne[0], query_tsne[1], marker='*', color='green', s=300, label='Query', edgecolor=\"k\")\n",
    "\n",
    "    # Create annotations with adjust_text\n",
    "    texts = []\n",
    "    for i, (x, y) in enumerate(doc_tsne):\n",
    "        texts.append(plt.text(x, y, f\"Sim: {cosine_similarities[i]:.2f}\", \n",
    "                              ha='center', va='center', fontsize=8,\n",
    "                              bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.7, ec='none')))\n",
    "\n",
    "    # Annotate the query separately\n",
    "    query_text = plt.text(query_tsne[0], query_tsne[1], \"Query\", \n",
    "                          ha='center', va='center', fontsize=10, fontweight='bold',\n",
    "                          bbox=dict(boxstyle='round,pad=0.5', fc='lightgreen', alpha=0.7, ec='none'))\n",
    "\n",
    "    texts.append(query_text)\n",
    "\n",
    "    # Adjust text to avoid overlaps\n",
    "    adjust_text(texts, arrowprops=dict(arrowstyle='->', color='red', lw=0.5),\n",
    "                expand_points=(1.2, 1.2), force_points=(0.1, 0.1))\n",
    "\n",
    "    # Set plot labels and title\n",
    "    plt.title('t-SNE Visualization of Query and Retrieved Document Embeddings')\n",
    "    plt.xlabel('t-SNE Dimension 1')\n",
    "    plt.ylabel('t-SNE Dimension 2')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.autoscale()\n",
    "    plt.margins(0.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15d3f38-53be-43bc-a37a-f89e824629df",
   "metadata": {},
   "outputs": [],
   "source": [
    "oembed = OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "\n",
    "vectordb = Chroma(\n",
    "    persist_directory = \"text_reports/all_embed_db\",\n",
    "    embedding_function = oembed\n",
    ")\n",
    "\n",
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcd392f-d9a4-4d41-a6fa-7350f6c8883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ollamallm = ChatOllama(base_url=\"http://localhost:11434\", model=\"gemma2:2b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566361f0-9c9e-411c-9d06-09c8c30ea4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Query: Different Perspectives\n",
    "query_template = \"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
    "prompt_rag_fusion = ChatPromptTemplate.from_template(query_template)\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_rag_fusion  \n",
    "    | Ollamallm\n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30374d6-0072-4dfd-9158-ffac22df7033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(question, classifications):\n",
    "    classification = \", \".join([f\"{k}: {v:.2f}\" for k, v in classifications.items()])\n",
    "    \n",
    "    retrieval_chain = generate_queries | retriever.map() | reciprocal_rank_fusion\n",
    "    retrieved_docs = retrieval_chain.invoke({\"question\": question})\n",
    "\n",
    "    if not retrieved_docs:\n",
    "        print(\"No documents retrieved. Please check the retrieval process.\")\n",
    "        return None, None\n",
    "\n",
    "    # Get embeddings for the retrieved documents\n",
    "    doc_contents = [doc[0].page_content for doc in retrieved_docs]\n",
    "    doc_embeddings = oembed.embed_documents(doc_contents)\n",
    "\n",
    "    if not doc_embeddings:\n",
    "        print(\"Failed to generate document embeddings.\")\n",
    "        return None, None\n",
    "\n",
    "    # Embed the query\n",
    "    query_embedding = oembed.embed_query(question)\n",
    "\n",
    "    if query_embedding is None:\n",
    "        print(\"Failed to generate query embedding.\")\n",
    "        return None, None\n",
    "\n",
    "    # Calculate cosine similarities\n",
    "    cosine_similarities = calculate_cosine_similarity(query_embedding, doc_embeddings)\n",
    "\n",
    "    if cosine_similarities is None or len(cosine_similarities) == 0:\n",
    "        print(\"Failed to calculate cosine similarities.\")\n",
    "        return None, None\n",
    "\n",
    "    # Plot t-SNE\n",
    "    try:\n",
    "        plot_tsne(query_embedding, doc_embeddings, cosine_similarities)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in plotting t-SNE: {e}\")\n",
    "\n",
    "    # Print cosine similarities\n",
    "    print(\"Cosine Similarities between Query and Retrieved Documents:\")\n",
    "    for i, sim in enumerate(cosine_similarities):\n",
    "        print(f\"Document {i+1}: Cosine Similarity = {sim:.4f}\")\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    You are an expert radiologist. Generate a concise and accurate radiology report based on the provided context and classification. Follow these strict guidelines:\n",
    "    \n",
    "    1. Use ONLY the given template structure. Do not add any sections or text outside this structure.\n",
    "    2. Keep EXAMINATION, INDICATION, TECHNIQUE, and COMPARISON brief, as link sample report.\n",
    "    3. FINDINGS should be detailed but focused, describing only relevant observations.\n",
    "    4. IMPRESSION should summarize key findings and their clinical significance concisely.\n",
    "    5. Do not include any introductory or concluding statements, notifications, or recommendations unless explicitly part of the findings or impression.\n",
    "    6. Use appropriate medical terminology and maintain a professional tone.\n",
    "    7. Base your report solely on the given context and classification.\n",
    "    \n",
    "    Classification: {classification}\n",
    "    \n",
    "    Context: {context}\n",
    "    \n",
    "    Generate the report now, strictly following the template below:\n",
    "    {report_template}\n",
    "\n",
    "    Here's a sample report for reference:\n",
    "    {sample_report}\n",
    "    \"\"\")\n",
    "    \n",
    "    final_rag_chain = (\n",
    "        {\n",
    "            \"context\": itemgetter(\"context\"),\n",
    "            \"question\": itemgetter(\"question\"),\n",
    "            \"classification\": lambda x: classification,\n",
    "            \"sample_report\": lambda x: sample_report,\n",
    "            \"report_template\": lambda x: report_template\n",
    "        }\n",
    "        | prompt\n",
    "        | Ollamallm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    generated_report = final_rag_chain.invoke({\"context\": retrieved_docs, \"question\": question})\n",
    "    \n",
    "    return generated_report, cosine_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f5d229-662d-4630-ac35-967677f0d792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_images_in_directory(image_dir, report_dir, output_csv=None):\n",
    "    results = []\n",
    "    similarities_data = []\n",
    "\n",
    "    for image_filename in os.listdir(image_dir):\n",
    "        image_path = os.path.join(image_dir, image_filename)\n",
    "        \n",
    "        if not image_filename.lower().endswith(('.jpg', '.png')):\n",
    "            continue\n",
    "        \n",
    "        classifications = predict_image(image_path)\n",
    "        top_classifications = get_top_classifications(classifications)\n",
    "\n",
    "        question = f\"Retrieve radiology reports that diagnose or mention {', '.join([f'{k}: {v:.2f}' for k, v in top_classifications.items()])}. Based on the provided chest X-ray images, detail the relevant radiographic findings and their clinical significance.\"\n",
    "\n",
    "        generated_report, cosine_similarities = generate_report(question, top_classifications)\n",
    "        \n",
    "        if generated_report is None or cosine_similarities is None:\n",
    "            print(f\"Skipping image {image_filename} due to error in report generation.\")\n",
    "            continue\n",
    "        \n",
    "        # Save cosine similarities for each document retrieved\n",
    "        for i, sim in enumerate(cosine_similarities):\n",
    "            similarities_data.append({\n",
    "                'image_name': image_filename,\n",
    "                'document_number': i + 1,\n",
    "                'cosine_similarity': sim\n",
    "            })\n",
    "\n",
    "        # Find and read the original report (if available)\n",
    "        report_filename = image_filename.rsplit('.', 1)[0] + '.txt'\n",
    "        original_report_path = os.path.join(report_dir, report_filename)\n",
    "        \n",
    "        original_report = ''\n",
    "        try:\n",
    "            with open(original_report_path, 'r') as file:\n",
    "                original_report = file.read()\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: Original report not found for {report_filename}\")\n",
    "\n",
    "        # Append results to the list\n",
    "        results.append({\n",
    "            'image_name': image_filename,\n",
    "            'Classification': top_classifications,\n",
    "            'generated_report': generated_report,\n",
    "            'original_report': original_report\n",
    "        })\n",
    "\n",
    "    # Convert results to a DataFrame and save as CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    similarities_df = pd.DataFrame(similarities_data)\n",
    "\n",
    "    if output_csv:\n",
    "        results_csv_path = output_csv if output_csv.endswith('.csv') else output_csv + 'ggegemgemagema2_reports.csv'\n",
    "        similarities_csv_path = output_csv if output_csv.endswith('.csv') else output_csv + 'gemma2_similarities.csv'\n",
    "        \n",
    "        results_df.to_csv(results_csv_path, index=False)\n",
    "        similarities_df.to_csv(similarities_csv_path, index=False)\n",
    "        print(f\"Reports saved to CSV file: {results_csv_path}\")\n",
    "        print(f\"Similarities saved to CSV file: {similarities_csv_path}\")\n",
    "    else:\n",
    "        print(\"Output CSV path is not provided.\")\n",
    "    \n",
    "    return results_df, similarities_df\n",
    "\n",
    "# Example usage\n",
    "image_directory ='path_to_directory'\n",
    "report_directory = 'path_to_directory'\n",
    "output_csv_base = 'path_to_directory'\n",
    "\n",
    "process_all_images_in_directory(image_directory, report_directory, output_csv_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c09fbb7-a61f-47cd-a58c-51c2a356dbb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
